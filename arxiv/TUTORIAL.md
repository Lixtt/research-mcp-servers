# arXiv MCP æœåŠ¡å™¨æ•™ç¨‹

## ç®€ä»‹

arXiv MCP æœåŠ¡å™¨æ˜¯ä¸€ä¸ªåŸºäº FastMCP æ¡†æ¶çš„å·¥å…·ï¼Œæä¾›å¯¹ arXiv è®ºæ–‡æ•°æ®åº“çš„å®Œæ•´è®¿é—®åŠŸèƒ½ã€‚å®ƒæ”¯æŒè®ºæ–‡æœç´¢ã€ä¸‹è½½ã€é˜…è¯»å’Œç®¡ç†ï¼Œæ˜¯å­¦æœ¯ç ”ç©¶çš„å¼ºå¤§åŠ©æ‰‹ã€‚

## åŠŸèƒ½ç‰¹æ€§

- ğŸ” **æ™ºèƒ½æœç´¢**: æ”¯æŒå…³é”®è¯ã€ä½œè€…ã€åˆ†ç±»ã€æ—¥æœŸèŒƒå›´ç­‰å¤šç§æœç´¢æ–¹å¼
- ğŸ“¥ **æ‰¹é‡ä¸‹è½½**: æ”¯æŒå•ç¯‡æˆ–æ‰¹é‡ä¸‹è½½è®ºæ–‡ PDF
- ğŸ“– **æ–‡æœ¬æå–**: ä» PDF ä¸­æå–æ–‡æœ¬å†…å®¹è¿›è¡Œåˆ†æ
- ğŸ“ **æœ¬åœ°ç®¡ç†**: è‡ªåŠ¨ç®¡ç†ä¸‹è½½çš„è®ºæ–‡æ–‡ä»¶
- ğŸ”— **ç‰ˆæœ¬æ”¯æŒ**: æ”¯æŒç‰¹å®šç‰ˆæœ¬çš„è®ºæ–‡ä¸‹è½½

## å®‰è£…å’Œé…ç½®

### 1. å®‰è£…ä¾èµ–

```bash
pip install -r requirements.txt
```

### 2. MCP å®¢æˆ·ç«¯é…ç½®

åœ¨ Claude Desktop çš„é…ç½®æ–‡ä»¶ä¸­æ·»åŠ  arXiv æœåŠ¡å™¨é…ç½®ï¼š

**Windows**: `%APPDATA%\Claude\claude_desktop_config.json`
**macOS**: `~/Library/Application Support/Claude/claude_desktop_config.json`

```json
{
  "mcpServers": {
    "arxiv": {
      "command": "python",
      "args": ["C:\\path\\to\\research-mcp-servers\\arxiv\\arxiv_server.py"],
      "env": {
        "PYTHONPATH": "C:\\path\\to\\research-mcp-servers",
        "PYTHONUNBUFFERED": "1"
      }
    }
  }
}
```

**æ³¨æ„**: è¯·å°†è·¯å¾„æ›¿æ¢ä¸ºæ‚¨çš„å®é™…é¡¹ç›®è·¯å¾„ã€‚å¦‚æœä½¿ç”¨è™šæ‹Ÿç¯å¢ƒï¼Œå°† `"command": "python"` æ”¹ä¸ºè™šæ‹Ÿç¯å¢ƒä¸­ Python çš„å®Œæ•´è·¯å¾„ã€‚

### 3. å¯åŠ¨æœåŠ¡å™¨

```bash
# æ ‡å‡†æ¨¡å¼ï¼ˆç”¨äº MCP å®¢æˆ·ç«¯ï¼‰
python arxiv_server.py

# HTTP æ¨¡å¼ï¼ˆç”¨äº Web åº”ç”¨ï¼‰
python arxiv_server.py --transport http --port 8000

# è‡ªå®šä¹‰ç«¯å£å’Œä¸»æœº
python arxiv_server.py --transport http --host 0.0.0.0 --port 9000
```

### 4. é…ç½®éªŒè¯

#### æ£€æŸ¥æœåŠ¡å™¨çŠ¶æ€

```bash
# å¯åŠ¨ HTTP æ¨¡å¼å¹¶æ£€æŸ¥å¥åº·çŠ¶æ€
python arxiv_server.py --transport http --port 8000

# åœ¨å¦ä¸€ä¸ªç»ˆç«¯ä¸­æ£€æŸ¥å¥åº·çŠ¶æ€
curl http://localhost:8000/arxiv/health
```

#### å¯ç”¨å·¥å…·åˆ—è¡¨

é…ç½®æˆåŠŸåï¼ŒMCP å®¢æˆ·ç«¯å°†å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å·¥å…·ï¼š

1. **`arxiv_query`** - æœç´¢å’ŒæŸ¥è¯¢ arXiv è®ºæ–‡
2. **`download_paper`** - ä¸‹è½½è®ºæ–‡ PDF æ–‡ä»¶
3. **`list_downloaded_papers`** - åˆ—å‡ºæœ¬åœ°å·²ä¸‹è½½çš„è®ºæ–‡
4. **`read_paper`** - è¯»å–å·²ä¸‹è½½è®ºæ–‡çš„æ–‡æœ¬å†…å®¹

#### é…ç½®æ•…éšœæ’é™¤

**å¸¸è§é—®é¢˜ï¼š**

1. **è·¯å¾„é”™è¯¯** - ç¡®ä¿ä½¿ç”¨æ­£ç¡®çš„ç»å¯¹è·¯å¾„
2. **Python ç¯å¢ƒé—®é¢˜** - ä½¿ç”¨å®Œæ•´è·¯å¾„åˆ° Python è§£é‡Šå™¨
3. **æƒé™é—®é¢˜** - ç¡®ä¿æœ‰æ‰§è¡Œæƒé™
4. **ä¾èµ–ç¼ºå¤±** - è¿è¡Œ `pip install -r requirements.txt` å®‰è£…æ‰€æœ‰ä¾èµ–

## æ ¸å¿ƒå·¥å…·ä½¿ç”¨

### 1. è®ºæ–‡æœç´¢ (`arxiv_query`)

#### åŸºæœ¬æœç´¢
```python
# å…³é”®è¯æœç´¢
papers = await arxiv_query("machine learning transformers")

# ä½œè€…æœç´¢
papers = await arxiv_query("au:Hinton")

# åˆ†ç±»æœç´¢
papers = await arxiv_query("cat:cs.AI")
```

#### é«˜çº§æœç´¢è¯­æ³•
```python
# å¤åˆæŸ¥è¯¢
papers = await arxiv_query("cat:cs.AI AND au:Bengio AND submittedDate:[202301010000 TO 202312312359]")

# æ ‡é¢˜æœç´¢
papers = await arxiv_query("ti:transformer")

# æ‘˜è¦æœç´¢
papers = await arxiv_query("abs:deep learning")
```

#### æŒ‰ ID æŸ¥è¯¢
```python
# å•ç¯‡è®ºæ–‡
papers = await arxiv_query(id_list="2401.12345")

# å¤šç¯‡è®ºæ–‡
papers = await arxiv_query(id_list=["2401.12345", "1909.03550", "2312.11805"])

# ç‰¹å®šç‰ˆæœ¬
papers = await arxiv_query(id_list="1706.03762v1")
```

### 2. è®ºæ–‡ä¸‹è½½ (`download_paper`)

#### å•ç¯‡ä¸‹è½½
```python
# ä¸‹è½½æœ€æ–°ç‰ˆæœ¬
result = await download_paper("2401.12345")

# ä¸‹è½½ç‰¹å®šç‰ˆæœ¬
result = await download_paper("2401.12345v1")

# æŒ‡å®šä¿å­˜ç›®å½•
result = await download_paper("2401.12345", "/path/to/papers")
```

#### æ‰¹é‡ä¸‹è½½
```python
# æ‰¹é‡ä¸‹è½½
results = await download_paper(["2401.12345", "1909.03550", "2312.11805"])

# æ‰¹é‡ä¸‹è½½åˆ°æŒ‡å®šç›®å½•
results = await download_paper(["2401.12345", "1909.03550"], "/home/user/papers")
```

### 3. æœ¬åœ°è®ºæ–‡ç®¡ç† (`list_downloaded_papers`)

```python
# åˆ—å‡ºæ‰€æœ‰ä¸‹è½½çš„è®ºæ–‡
papers = await list_downloaded_papers()

# åŒ…å«å†…å®¹é¢„è§ˆ
papers = await list_downloaded_papers(include_content_preview=True)

# æŒ‡å®šç›®å½•
papers = await list_downloaded_papers("/path/to/papers")
```

### 4. è®ºæ–‡é˜…è¯» (`read_paper`)

```python
# é€šè¿‡æ–‡ä»¶è·¯å¾„é˜…è¯»
content = await read_paper(filepath="/path/to/paper.pdf")

# é€šè¿‡ arXiv ID é˜…è¯»
content = await read_paper(paper_id="2401.12345")

# é™åˆ¶é¡µæ•°å’Œå­—ç¬¦æ•°
content = await read_paper(paper_id="2401.12345", max_pages=5, max_chars=50000)
```

## æœç´¢è¯­æ³•å‚è€ƒ

### åŸºæœ¬è¯­æ³•
- `å…³é”®è¯`: åœ¨æ ‡é¢˜ã€æ‘˜è¦ã€ä½œè€…ä¸­æœç´¢
- `au:ä½œè€…å`: æœç´¢ç‰¹å®šä½œè€…
- `ti:æ ‡é¢˜`: åœ¨æ ‡é¢˜ä¸­æœç´¢
- `abs:æ‘˜è¦`: åœ¨æ‘˜è¦ä¸­æœç´¢
- `cat:åˆ†ç±»`: æœç´¢ç‰¹å®šåˆ†ç±»
- `id:è®ºæ–‡ID`: æœç´¢ç‰¹å®šè®ºæ–‡

### é€»è¾‘æ“ä½œç¬¦
- `AND`: é€»è¾‘ä¸
- `OR`: é€»è¾‘æˆ–
- `ANDNOT`: é€»è¾‘é

### æ—¥æœŸèŒƒå›´
```python
# 2023å¹´1æœˆ1æ—¥åˆ°2023å¹´12æœˆ31æ—¥
"submittedDate:[202301010000 TO 202312312359]"

# 2024å¹´1æœˆ1æ—¥ä¹‹å
"submittedDate:[202401010000 TO *]"
```

### åˆ†ç±»ä»£ç 
- `cs.AI`: äººå·¥æ™ºèƒ½
- `cs.LG`: æœºå™¨å­¦ä¹ 
- `cs.CL`: è®¡ç®—è¯­è¨€å­¦
- `cs.CV`: è®¡ç®—æœºè§†è§‰
- `math.NA`: æ•°å€¼åˆ†æ
- `physics.gen-ph`: ä¸€èˆ¬ç‰©ç†

## å®é™…åº”ç”¨ç¤ºä¾‹

### 1. ç ”ç©¶è¶‹åŠ¿åˆ†æ
```python
# æœç´¢æœ€è¿‘ä¸€å¹´çš„ AI è®ºæ–‡
recent_ai_papers = await arxiv_query(
    "cat:cs.AI AND submittedDate:[202301010000 TO 202312312359]",
    max_results=50,
    sortBy="submittedDate"
)
```

### 2. ç‰¹å®šä½œè€…è·Ÿè¸ª
```python
# è·Ÿè¸ªç‰¹å®šä½œè€…çš„æœ€æ–°å·¥ä½œ
author_papers = await arxiv_query(
    "au:Hinton AND submittedDate:[202301010000 TO *]",
    sortBy="submittedDate"
)
```

### 3. æ‰¹é‡ä¸‹è½½å’Œé˜…è¯»
```python
# ä¸‹è½½ç›¸å…³è®ºæ–‡
paper_ids = ["2401.12345", "1909.03550", "2312.11805"]
download_results = await download_paper(paper_ids)

# é˜…è¯»è®ºæ–‡å†…å®¹
for paper_id in paper_ids:
    content = await read_paper(paper_id=paper_id, max_pages=3)
    print(f"è®ºæ–‡ {paper_id} çš„å‰3é¡µå†…å®¹:")
    print(content[:1000] + "...")
```

## æœ€ä½³å®è·µ

### 1. æœç´¢ä¼˜åŒ–
- ä½¿ç”¨å…·ä½“çš„åˆ†ç±»ä»£ç è€Œä¸æ˜¯é€šç”¨å…³é”®è¯
- ç»“åˆä½œè€…å’Œåˆ†ç±»è¿›è¡Œç²¾ç¡®æœç´¢
- åˆ©ç”¨æ—¥æœŸèŒƒå›´é™åˆ¶æœç´¢ç»“æœ

### 2. ä¸‹è½½ç®¡ç†
- å®šæœŸæ¸…ç†ä¸éœ€è¦çš„è®ºæ–‡æ–‡ä»¶
- ä½¿ç”¨æœ‰æ„ä¹‰çš„ç›®å½•ç»“æ„
- æ‰¹é‡ä¸‹è½½æ—¶æ³¨æ„ç½‘ç»œè¿æ¥ç¨³å®šæ€§

### 3. å†…å®¹åˆ†æ
- å…ˆé˜…è¯»æ‘˜è¦å’Œå¼•è¨€éƒ¨åˆ†
- ä½¿ç”¨ `max_pages` å‚æ•°æ§åˆ¶é˜…è¯»é‡
- ç»“åˆ `list_downloaded_papers` ç®¡ç†æœ¬åœ°æ–‡ä»¶

## æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **ç½‘ç»œè¿æ¥é”™è¯¯**
   - æ£€æŸ¥ç½‘ç»œè¿æ¥
   - ç¡®è®¤ arXiv API å¯è®¿é—®æ€§

2. **PDF è¯»å–å¤±è´¥**
   - ç¡®ä¿å®‰è£…äº† PyMuPDF
   - æ£€æŸ¥ PDF æ–‡ä»¶å®Œæ•´æ€§

3. **æœç´¢ç»“æœä¸ºç©º**
   - æ£€æŸ¥æœç´¢è¯­æ³•
   - å°è¯•æ›´å®½æ³›çš„æœç´¢æ¡ä»¶

### è°ƒè¯•æ¨¡å¼
```bash
# å¯ç”¨è¯¦ç»†æ—¥å¿—
python arxiv_server.py --transport http --port 8000
```

## æ‰©å±•åŠŸèƒ½

### è‡ªå®šä¹‰æœç´¢
```python
# åˆ›å»ºè‡ªå®šä¹‰æœç´¢å‡½æ•°
async def search_recent_papers(category, days=30):
    from datetime import datetime, timedelta
    end_date = datetime.now()
    start_date = end_date - timedelta(days=days)
    
    date_range = f"submittedDate:[{start_date.strftime('%Y%m%d%H%M')} TO {end_date.strftime('%Y%m%d%H%M')}]"
    return await arxiv_query(f"cat:{category} AND {date_range}")
```

### è®ºæ–‡åˆ†æ
```python
# åˆ†æè®ºæ–‡å…³é”®è¯
async def analyze_paper_keywords(paper_id):
    content = await read_paper(paper_id=paper_id, max_pages=2)
    # åœ¨è¿™é‡Œæ·»åŠ å…³é”®è¯æå–é€»è¾‘
    return content
```

## æµ‹è¯•é…ç½®

é…ç½®å®Œæˆåï¼Œå¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹å¼æµ‹è¯•ï¼š

1. **é‡å¯ Claude Desktop**
2. **æ£€æŸ¥å·¥å…·å¯ç”¨æ€§**ï¼šåœ¨ Claude ä¸­è¯¢é—® "æœ‰å“ªäº›å¯ç”¨çš„å·¥å…·ï¼Ÿ"
3. **æµ‹è¯•åŸºæœ¬åŠŸèƒ½**ï¼šå°è¯•æœç´¢ä¸€ç¯‡è®ºæ–‡

```bash
# æµ‹è¯•å‘½ä»¤ç¤ºä¾‹
python arxiv_server.py --transport http --port 8000
curl http://localhost:8000/arxiv/health
```

## æ€»ç»“

arXiv MCP æœåŠ¡å™¨ä¸ºå­¦æœ¯ç ”ç©¶æä¾›äº†å¼ºå¤§çš„å·¥å…·é›†ï¼Œé€šè¿‡åˆç†çš„æœç´¢ç­–ç•¥å’Œæ‰¹é‡æ“ä½œï¼Œå¯ä»¥å¤§å¤§æé«˜ç ”ç©¶æ•ˆç‡ã€‚å»ºè®®ä»ç®€å•çš„å…³é”®è¯æœç´¢å¼€å§‹ï¼Œé€æ­¥æŒæ¡é«˜çº§æœç´¢è¯­æ³•å’Œæ‰¹é‡æ“ä½œæŠ€å·§ã€‚

### å¿«é€Ÿå¼€å§‹æ£€æŸ¥æ¸…å•

- [ ] å®‰è£…ä¾èµ–ï¼š`pip install -r requirements.txt`
- [ ] é…ç½® MCP å®¢æˆ·ç«¯ï¼ˆClaude Desktop ç­‰ï¼‰
- [ ] æµ‹è¯•æœåŠ¡å™¨è¿æ¥
- [ ] å°è¯•åŸºæœ¬æœç´¢åŠŸèƒ½
- [ ] ä¸‹è½½å¹¶é˜…è¯»ç¬¬ä¸€ç¯‡è®ºæ–‡
- [ ] æ¢ç´¢é«˜çº§æœç´¢è¯­æ³•
