# arXiv MCP æœåŠ¡å™¨æ•™ç¨‹

## ç®€ä»‹

arXiv MCP æœåŠ¡å™¨æ˜¯ä¸€ä¸ªåŸºäº FastMCP æ¡†æ¶çš„å·¥å…·ï¼Œæä¾›å¯¹ arXiv è®ºæ–‡æ•°æ®åº“çš„å®Œæ•´è®¿é—®åŠŸèƒ½ã€‚å®ƒæ”¯æŒè®ºæ–‡æœç´¢ã€ä¸‹è½½ã€é˜…è¯»å’Œç®¡ç†ï¼Œæ˜¯å­¦æœ¯ç ”ç©¶çš„å¼ºå¤§åŠ©æ‰‹ã€‚

## åŠŸèƒ½ç‰¹æ€§

- ğŸ” **æ™ºèƒ½æœç´¢**: æ”¯æŒå…³é”®è¯ã€ä½œè€…ã€åˆ†ç±»ã€æ—¥æœŸèŒƒå›´ç­‰å¤šç§æœç´¢æ–¹å¼
- ğŸ“¥ **æ‰¹é‡ä¸‹è½½**: æ”¯æŒå•ç¯‡æˆ–æ‰¹é‡ä¸‹è½½è®ºæ–‡ PDF
- ğŸ“– **æ–‡æœ¬æå–**: ä» PDF ä¸­æå–æ–‡æœ¬å†…å®¹è¿›è¡Œåˆ†æ
- ğŸ–¼ï¸ **å›¾åƒæå–**: å°† PDF é¡µé¢è½¬æ¢ä¸ºå›¾åƒï¼Œæ”¯æŒ AI è§†è§‰åˆ†æ
- ğŸ“ **æœ¬åœ°ç®¡ç†**: è‡ªåŠ¨ç®¡ç†ä¸‹è½½çš„è®ºæ–‡æ–‡ä»¶
- ğŸ”— **ç‰ˆæœ¬æ”¯æŒ**: æ”¯æŒç‰¹å®šç‰ˆæœ¬çš„è®ºæ–‡ä¸‹è½½

## å®‰è£…å’Œé…ç½®

### 1. å®‰è£…ä¾èµ–

```bash
pip install -r requirements.txt
```

### 2. MCP å®¢æˆ·ç«¯é…ç½®

åœ¨ Claude Desktop çš„é…ç½®æ–‡ä»¶ä¸­æ·»åŠ  arXiv æœåŠ¡å™¨é…ç½®ï¼š

**Windows**: `%APPDATA%\Claude\claude_desktop_config.json`
**macOS**: `~/Library/Application Support/Claude/claude_desktop_config.json`

```json
{
  "mcpServers": {
    "arxiv": {
      "command": "python",
      "args": ["C:\\path\\to\\research-mcp-servers\\arxiv\\arxiv_server.py"],
      "env": {
        "PYTHONPATH": "C:\\path\\to\\research-mcp-servers",
        "PYTHONUNBUFFERED": "1"
      }
    }
  }
}
```

**æ³¨æ„**: è¯·å°†è·¯å¾„æ›¿æ¢ä¸ºæ‚¨çš„å®é™…é¡¹ç›®è·¯å¾„ã€‚å¦‚æœä½¿ç”¨è™šæ‹Ÿç¯å¢ƒï¼Œå°† `"command": "python"` æ”¹ä¸ºè™šæ‹Ÿç¯å¢ƒä¸­ Python çš„å®Œæ•´è·¯å¾„ã€‚

### 3. å¯åŠ¨æœåŠ¡å™¨

```bash
# æ ‡å‡†æ¨¡å¼ï¼ˆç”¨äº MCP å®¢æˆ·ç«¯ï¼‰
python arxiv_server.py

# HTTP æ¨¡å¼ï¼ˆç”¨äº Web åº”ç”¨ï¼‰
python arxiv_server.py --transport http --port 8000

# è‡ªå®šä¹‰ç«¯å£å’Œä¸»æœº
python arxiv_server.py --transport http --host 0.0.0.0 --port 9000
```

### 4. é…ç½®éªŒè¯

#### æ£€æŸ¥æœåŠ¡å™¨çŠ¶æ€

```bash
# å¯åŠ¨ HTTP æ¨¡å¼å¹¶æ£€æŸ¥å¥åº·çŠ¶æ€
python arxiv_server.py --transport http --port 8000

# åœ¨å¦ä¸€ä¸ªç»ˆç«¯ä¸­æ£€æŸ¥å¥åº·çŠ¶æ€
curl http://localhost:8000/arxiv/health
```

#### å¯ç”¨å·¥å…·åˆ—è¡¨

é…ç½®æˆåŠŸåï¼ŒMCP å®¢æˆ·ç«¯å°†å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å·¥å…·ï¼š

1. **`arxiv_query`** - æœç´¢å’ŒæŸ¥è¯¢ arXiv è®ºæ–‡
2. **`download_paper`** - ä¸‹è½½è®ºæ–‡ PDF æ–‡ä»¶
3. **`list_downloaded_papers`** - åˆ—å‡ºæœ¬åœ°å·²ä¸‹è½½çš„è®ºæ–‡
4. **`read_paper`** - è¯»å–å·²ä¸‹è½½è®ºæ–‡çš„æ–‡æœ¬å†…å®¹
5. **`get_paper_resources`** - ç”Ÿæˆ MCP èµ„æº URIï¼Œæ”¯æŒå›¾åƒã€å…ƒæ•°æ®å’Œæ–‡æœ¬èµ„æº

#### MCP èµ„æºæ”¯æŒ

æœåŠ¡å™¨è¿˜æä¾› MCP èµ„æºåŠŸèƒ½ï¼Œæ”¯æŒä»¥ä¸‹èµ„æºç±»å‹ï¼š

- **å›¾åƒèµ„æº**: `arxiv://{paper_id}/image/{page}?dpi={dpi}` - è®ºæ–‡é¡µé¢å›¾åƒ
- **å…ƒæ•°æ®èµ„æº**: `arxiv://{paper_id}/metadata` - è®ºæ–‡å…ƒæ•°æ®ä¿¡æ¯
- **æ–‡æœ¬èµ„æº**: `arxiv://{paper_id}/text?pages={max_pages}` - è®ºæ–‡æ–‡æœ¬å†…å®¹

#### é…ç½®æ•…éšœæ’é™¤

**å¸¸è§é—®é¢˜ï¼š**

1. **è·¯å¾„é”™è¯¯** - ç¡®ä¿ä½¿ç”¨æ­£ç¡®çš„ç»å¯¹è·¯å¾„
2. **Python ç¯å¢ƒé—®é¢˜** - ä½¿ç”¨å®Œæ•´è·¯å¾„åˆ° Python è§£é‡Šå™¨
3. **æƒé™é—®é¢˜** - ç¡®ä¿æœ‰æ‰§è¡Œæƒé™
4. **ä¾èµ–ç¼ºå¤±** - è¿è¡Œ `pip install -r requirements.txt` å®‰è£…æ‰€æœ‰ä¾èµ–

## æ ¸å¿ƒå·¥å…·ä½¿ç”¨

### 1. è®ºæ–‡æœç´¢ (`arxiv_query`)

#### åŸºæœ¬æœç´¢
```python
# å…³é”®è¯æœç´¢
papers = await arxiv_query("machine learning transformers")

# ä½œè€…æœç´¢
papers = await arxiv_query("au:Hinton")

# åˆ†ç±»æœç´¢
papers = await arxiv_query("cat:cs.AI")
```

#### é«˜çº§æœç´¢è¯­æ³•
```python
# å¤åˆæŸ¥è¯¢
papers = await arxiv_query("cat:cs.AI AND au:Bengio AND submittedDate:[202301010000 TO 202312312359]")

# æ ‡é¢˜æœç´¢
papers = await arxiv_query("ti:transformer")

# æ‘˜è¦æœç´¢
papers = await arxiv_query("abs:deep learning")
```

#### æŒ‰ ID æŸ¥è¯¢
```python
# å•ç¯‡è®ºæ–‡
papers = await arxiv_query(id_list="2401.12345")

# å¤šç¯‡è®ºæ–‡
papers = await arxiv_query(id_list=["2401.12345", "1909.03550", "2312.11805"])

# ç‰¹å®šç‰ˆæœ¬
papers = await arxiv_query(id_list="1706.03762v1")
```

### 2. è®ºæ–‡ä¸‹è½½ (`download_paper`)

#### å•ç¯‡ä¸‹è½½
```python
# ä¸‹è½½æœ€æ–°ç‰ˆæœ¬
result = await download_paper("2401.12345")

# ä¸‹è½½ç‰¹å®šç‰ˆæœ¬
result = await download_paper("2401.12345v1")

# æŒ‡å®šä¿å­˜ç›®å½•
result = await download_paper("2401.12345", "/path/to/papers")
```

#### æ‰¹é‡ä¸‹è½½
```python
# æ‰¹é‡ä¸‹è½½
results = await download_paper(["2401.12345", "1909.03550", "2312.11805"])

# æ‰¹é‡ä¸‹è½½åˆ°æŒ‡å®šç›®å½•
results = await download_paper(["2401.12345", "1909.03550"], "/home/user/papers")
```

### 3. æœ¬åœ°è®ºæ–‡ç®¡ç† (`list_downloaded_papers`)

```python
# åˆ—å‡ºæ‰€æœ‰ä¸‹è½½çš„è®ºæ–‡
papers = await list_downloaded_papers()

# åŒ…å«å†…å®¹é¢„è§ˆ
papers = await list_downloaded_papers(include_content_preview=True)

# æŒ‡å®šç›®å½•
papers = await list_downloaded_papers("/path/to/papers")
```

### 4. è®ºæ–‡é˜…è¯» (`read_paper`)

```python
# é€šè¿‡æ–‡ä»¶è·¯å¾„é˜…è¯»
content = await read_paper(filepath="/path/to/paper.pdf")

# é€šè¿‡ arXiv ID é˜…è¯»
content = await read_paper(paper_id="2401.12345")

# é™åˆ¶é¡µæ•°å’Œå­—ç¬¦æ•°
content = await read_paper(paper_id="2401.12345", max_pages=5, max_chars=50000)
```

### 5. MCP èµ„æºç”Ÿæˆ (`get_paper_resources`)

è¿™æ˜¯æ¨èçš„æ–°æ–¹å¼ï¼Œç”¨äºç”Ÿæˆå¯åœ¨å¯¹è¯ä¸­ç›´æ¥å¼•ç”¨çš„ MCP èµ„æº URIï¼š

```python
# ç”Ÿæˆå›¾åƒèµ„æº
resources = await get_paper_resources(
    paper_id="2401.12345",
    resource_types=["image"],
    max_pages=3,
    dpi=150
)

# ç”Ÿæˆæ‰€æœ‰ç±»å‹çš„èµ„æº
resources = await get_paper_resources(
    paper_id="2401.12345",
    resource_types=["image", "metadata", "text"],
    max_pages=5,
    dpi=200
)
```

**è¿”å›æ ¼å¼**ï¼š
```python
{
    "images": [
        {
            "uri": "arxiv://2401.12345/image/1?dpi=150",
            "page_number": 1,
            "paper_id": "2401.12345",
            "dpi": 150,
            "resource_type": "image",
            "description": "Page 1 of arXiv paper 2401.12345 as image",
            "usage": "Reference this URI in conversation - MCP clients will show the image"
        },
        # ... æ›´å¤šé¡µé¢
    ],
    "metadata": {
        "uri": "arxiv://2401.12345/metadata",
        "paper_id": "2401.12345",
        "resource_type": "metadata",
        "description": "Complete metadata for arXiv paper 2401.12345",
        "usage": "Reference this URI to get paper title, authors, abstract, etc."
    },
    "text": {
        "uri": "arxiv://2401.12345/text?pages=3",
        "paper_id": "2401.12345",
        "max_pages": 3,
        "resource_type": "text",
        "description": "Text content of arXiv paper 2401.12345 (first 3 pages)",
        "usage": "Reference this URI to get the paper's text content"
    },
    "summary": "Generated 3 resource type(s) for paper 2401.12345",
    "usage_instructions": [
        "Copy any URI from the results and reference it directly in your conversation",
        "Example: 'Please analyze this image: arxiv://1706.03762/image/1'",
        "Compatible MCP clients will automatically load the referenced resources"
    ]
}
```

### 6. åœ¨å¯¹è¯ä¸­ä½¿ç”¨ MCP èµ„æº

ç”Ÿæˆèµ„æºåï¼Œå¯ä»¥ç›´æ¥åœ¨å¯¹è¯ä¸­å¼•ç”¨è¿™äº› URIï¼š

```
è¯·åˆ†æè¿™ä¸ªè®ºæ–‡çš„ç¬¬ä¸€é¡µï¼šarxiv://2401.12345/image/1?dpi=150
```

```
æ˜¾ç¤ºè¿™ä¸ªè®ºæ–‡çš„å…ƒæ•°æ®ï¼šarxiv://2401.12345/metadata
```

```
è·å–è¿™ä¸ªè®ºæ–‡çš„æ–‡æœ¬å†…å®¹ï¼šarxiv://2401.12345/text?pages=3
```

å½“ä½ åœ¨å¯¹è¯ä¸­å¼•ç”¨è¿™äº› URI æ—¶ï¼Œå…¼å®¹çš„ MCP å®¢æˆ·ç«¯ï¼ˆå¦‚ Cherry Studioï¼‰ä¼šè‡ªåŠ¨åŠ è½½ç›¸åº”çš„èµ„æºå†…å®¹ã€‚

## æœç´¢è¯­æ³•å‚è€ƒ

### åŸºæœ¬è¯­æ³•
- `å…³é”®è¯`: åœ¨æ ‡é¢˜ã€æ‘˜è¦ã€ä½œè€…ä¸­æœç´¢
- `au:ä½œè€…å`: æœç´¢ç‰¹å®šä½œè€…
- `ti:æ ‡é¢˜`: åœ¨æ ‡é¢˜ä¸­æœç´¢
- `abs:æ‘˜è¦`: åœ¨æ‘˜è¦ä¸­æœç´¢
- `cat:åˆ†ç±»`: æœç´¢ç‰¹å®šåˆ†ç±»
- `id:è®ºæ–‡ID`: æœç´¢ç‰¹å®šè®ºæ–‡

### é€»è¾‘æ“ä½œç¬¦
- `AND`: é€»è¾‘ä¸
- `OR`: é€»è¾‘æˆ–
- `ANDNOT`: é€»è¾‘é

### æ—¥æœŸèŒƒå›´
```python
# 2023å¹´1æœˆ1æ—¥åˆ°2023å¹´12æœˆ31æ—¥
"submittedDate:[202301010000 TO 202312312359]"

# 2024å¹´1æœˆ1æ—¥ä¹‹å
"submittedDate:[202401010000 TO *]"
```

### åˆ†ç±»ä»£ç 
- `cs.AI`: äººå·¥æ™ºèƒ½
- `cs.LG`: æœºå™¨å­¦ä¹ 
- `cs.CL`: è®¡ç®—è¯­è¨€å­¦
- `cs.CV`: è®¡ç®—æœºè§†è§‰
- `math.NA`: æ•°å€¼åˆ†æ
- `physics.gen-ph`: ä¸€èˆ¬ç‰©ç†

## å®é™…åº”ç”¨ç¤ºä¾‹

### 1. ç ”ç©¶è¶‹åŠ¿åˆ†æ
```python
# æœç´¢æœ€è¿‘ä¸€å¹´çš„ AI è®ºæ–‡
recent_ai_papers = await arxiv_query(
    "cat:cs.AI AND submittedDate:[202301010000 TO 202312312359]",
    max_results=50,
    sortBy="submittedDate"
)
```

### 2. ç‰¹å®šä½œè€…è·Ÿè¸ª
```python
# è·Ÿè¸ªç‰¹å®šä½œè€…çš„æœ€æ–°å·¥ä½œ
author_papers = await arxiv_query(
    "au:Hinton AND submittedDate:[202301010000 TO *]",
    sortBy="submittedDate"
)
```

### 3. æ‰¹é‡ä¸‹è½½å’Œé˜…è¯»
```python
# ä¸‹è½½ç›¸å…³è®ºæ–‡
paper_ids = ["2401.12345", "1909.03550", "2312.11805"]
download_results = await download_paper(paper_ids)

# é˜…è¯»è®ºæ–‡å†…å®¹
for paper_id in paper_ids:
    content = await read_paper(paper_id=paper_id, max_pages=3)
    print(f"è®ºæ–‡ {paper_id} çš„å‰3é¡µå†…å®¹:")
    print(content[:1000] + "...")
```

### 4. MCP èµ„æºå·¥ä½œæµï¼ˆæ¨èï¼‰
```python
# ä¸‹è½½è®ºæ–‡
paper_id = "1706.03762"  # Attention Is All You Need
await download_paper(paper_id)

# ç”Ÿæˆ MCP èµ„æº
resources = await get_paper_resources(
    paper_id=paper_id,
    resource_types=["image", "metadata", "text"],
    max_pages=3,
    dpi=150
)

# æŸ¥çœ‹ç”Ÿæˆçš„èµ„æº
print("å›¾åƒèµ„æº:")
for img in resources["images"]:
    print(f"  - {img['uri']} (é¡µé¢ {img['page_number']})")

print("å…ƒæ•°æ®èµ„æº:")
print(f"  - {resources['metadata']['uri']}")

print("æ–‡æœ¬èµ„æº:")
print(f"  - {resources['text']['uri']}")

# åœ¨å¯¹è¯ä¸­ç›´æ¥å¼•ç”¨è¿™äº› URI
# ä¾‹å¦‚ï¼šè¯·åˆ†æè¿™ä¸ªè®ºæ–‡çš„ç¬¬ä¸€é¡µï¼šarxiv://1706.03762/image/1?dpi=150
```

### 5. ä¼ ç»Ÿå›¾åƒåˆ†æå·¥ä½œæµ
```python
# ä¸‹è½½è®ºæ–‡å¹¶æå–å›¾åƒï¼ˆä¼ ç»Ÿæ–¹å¼ï¼‰
paper_id = "1706.03762"  # Attention Is All You Need
await download_paper(paper_id)

# æå–å‰3é¡µä¸ºå›¾åƒ
images = await read_paper_as_images(
    paper_id=paper_id,
    max_pages=3,
    dpi=150
)

# æŸ¥çœ‹å›¾åƒä¿¡æ¯
for img in images:
    print(f"é¡µé¢ {img['page_number']}: {len(img['image_data'])} å­—ç¬¦çš„ base64 æ•°æ®")
    print(f"åˆ†è¾¨ç‡: {img['dpi']} DPI, æ ¼å¼: {img['format']}")

# å›¾åƒæ•°æ®å¯ä»¥ç›´æ¥ç”¨äº AI è§†è§‰åˆ†æ
# ä¾‹å¦‚ï¼šå‘é€ç»™æ”¯æŒè§†è§‰çš„ AI æ¨¡å‹è¿›è¡Œåˆ†æ
```

## æœ€ä½³å®è·µ

### 1. æœç´¢ä¼˜åŒ–
- ä½¿ç”¨å…·ä½“çš„åˆ†ç±»ä»£ç è€Œä¸æ˜¯é€šç”¨å…³é”®è¯
- ç»“åˆä½œè€…å’Œåˆ†ç±»è¿›è¡Œç²¾ç¡®æœç´¢
- åˆ©ç”¨æ—¥æœŸèŒƒå›´é™åˆ¶æœç´¢ç»“æœ

### 2. ä¸‹è½½ç®¡ç†
- å®šæœŸæ¸…ç†ä¸éœ€è¦çš„è®ºæ–‡æ–‡ä»¶
- ä½¿ç”¨æœ‰æ„ä¹‰çš„ç›®å½•ç»“æ„
- æ‰¹é‡ä¸‹è½½æ—¶æ³¨æ„ç½‘ç»œè¿æ¥ç¨³å®šæ€§

### 3. å†…å®¹åˆ†æ
- å…ˆé˜…è¯»æ‘˜è¦å’Œå¼•è¨€éƒ¨åˆ†
- ä½¿ç”¨ `max_pages` å‚æ•°æ§åˆ¶é˜…è¯»é‡
- ç»“åˆ `list_downloaded_papers` ç®¡ç†æœ¬åœ°æ–‡ä»¶

### 4. MCP èµ„æºä½¿ç”¨ä¼˜åŒ–
- **æ¨èä½¿ç”¨ MCP èµ„æº**ï¼šä¼˜å…ˆä½¿ç”¨ `get_paper_resources` ç”Ÿæˆå¯åœ¨å¯¹è¯ä¸­å¼•ç”¨çš„ URI
- **èµ„æºç±»å‹é€‰æ‹©**ï¼šæ ¹æ®éœ€è¦é€‰æ‹© `image`ã€`metadata`ã€`text` æˆ–ç»„åˆä½¿ç”¨
- **å›¾åƒå‚æ•°ä¼˜åŒ–**ï¼šè°ƒæ•´ DPI å‚æ•°å¹³è¡¡è´¨é‡å’Œæ–‡ä»¶å¤§å°ï¼ˆ150-200 æ¨èï¼‰
- **é¡µæ•°æ§åˆ¶**ï¼šé™åˆ¶ `max_pages` é¿å…ç”Ÿæˆè¿‡å¤§çš„èµ„æºæ•°æ®
- **å¯¹è¯é›†æˆ**ï¼šç”Ÿæˆçš„ URI å¯ä»¥ç›´æ¥åœ¨å¯¹è¯ä¸­å¼•ç”¨ï¼ŒMCP å®¢æˆ·ç«¯ä¼šè‡ªåŠ¨åŠ è½½å†…å®¹

### 5. å›¾åƒæå–ä¼˜åŒ–ï¼ˆä¼ ç»Ÿæ–¹å¼ï¼‰
- å¯¹äºåŒ…å«å¤§é‡å›¾è¡¨çš„è®ºæ–‡ï¼Œä½¿ç”¨å›¾åƒæå–è€Œéçº¯æ–‡æœ¬
- è°ƒæ•´ DPI å‚æ•°å¹³è¡¡è´¨é‡å’Œæ–‡ä»¶å¤§å°ï¼ˆ150-200 æ¨èï¼‰
- é™åˆ¶ `max_pages` é¿å…ç”Ÿæˆè¿‡å¤§çš„ base64 æ•°æ®
- å›¾åƒæ•°æ®é€‚åˆç”¨äº AI è§†è§‰åˆ†æå’Œ OCR è¯†åˆ«

## æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **ç½‘ç»œè¿æ¥é”™è¯¯**
   - æ£€æŸ¥ç½‘ç»œè¿æ¥
   - ç¡®è®¤ arXiv API å¯è®¿é—®æ€§

2. **PDF è¯»å–å¤±è´¥**
   - ç¡®ä¿å®‰è£…äº† PyMuPDF
   - æ£€æŸ¥ PDF æ–‡ä»¶å®Œæ•´æ€§

3. **æœç´¢ç»“æœä¸ºç©º**
   - æ£€æŸ¥æœç´¢è¯­æ³•
   - å°è¯•æ›´å®½æ³›çš„æœç´¢æ¡ä»¶

4. **å›¾åƒæå–å¤±è´¥**
   - ç¡®ä¿å®‰è£…äº† PyMuPDF
   - æ£€æŸ¥ PDF æ–‡ä»¶æ˜¯å¦æŸå
   - é™ä½ DPI è®¾ç½®æˆ–å‡å°‘é¡µæ•°

### è°ƒè¯•æ¨¡å¼
```bash
# å¯ç”¨è¯¦ç»†æ—¥å¿—
python arxiv_server.py --transport http --port 8000
```

## æ‰©å±•åŠŸèƒ½

### è‡ªå®šä¹‰æœç´¢
```python
# åˆ›å»ºè‡ªå®šä¹‰æœç´¢å‡½æ•°
async def search_recent_papers(category, days=30):
    from datetime import datetime, timedelta
    end_date = datetime.now()
    start_date = end_date - timedelta(days=days)
    
    date_range = f"submittedDate:[{start_date.strftime('%Y%m%d%H%M')} TO {end_date.strftime('%Y%m%d%H%M')}]"
    return await arxiv_query(f"cat:{category} AND {date_range}")
```

### è®ºæ–‡åˆ†æ
```python
# åˆ†æè®ºæ–‡å…³é”®è¯
async def analyze_paper_keywords(paper_id):
    content = await read_paper(paper_id=paper_id, max_pages=2)
    # åœ¨è¿™é‡Œæ·»åŠ å…³é”®è¯æå–é€»è¾‘
    return content
```

### MCP èµ„æºåˆ†æåŠŸèƒ½ï¼ˆæ¨èï¼‰
```python
# ç”Ÿæˆè®ºæ–‡çš„ MCP èµ„æºç”¨äºåˆ†æ
async def generate_paper_resources_for_analysis(paper_id, max_pages=5):
    resources = await get_paper_resources(
        paper_id=paper_id,
        resource_types=["image", "metadata", "text"],
        max_pages=max_pages,
        dpi=200  # é«˜åˆ†è¾¨ç‡ç”¨äºæ›´å¥½çš„è¯†åˆ«
    )
    
    # è¿”å›å¯ç”¨äºå¯¹è¯ä¸­å¼•ç”¨çš„èµ„æº URI
    return {
        "paper_id": paper_id,
        "image_uris": [img["uri"] for img in resources["images"]],
        "metadata_uri": resources["metadata"]["uri"],
        "text_uri": resources["text"]["uri"],
        "usage_examples": [
            f"è¯·åˆ†æè¿™ä¸ªè®ºæ–‡çš„ç¬¬ä¸€é¡µï¼š{resources['images'][0]['uri']}",
            f"æ˜¾ç¤ºè®ºæ–‡å…ƒæ•°æ®ï¼š{resources['metadata']['uri']}",
            f"è·å–è®ºæ–‡æ–‡æœ¬ï¼š{resources['text']['uri']}"
        ]
    }

# æ‰¹é‡ç”Ÿæˆå¤šä¸ªè®ºæ–‡çš„èµ„æº
async def batch_generate_resources(paper_ids, max_pages=3):
    all_resources = {}
    for paper_id in paper_ids:
        try:
            resources = await get_paper_resources(
                paper_id=paper_id,
                resource_types=["image", "metadata"],
                max_pages=max_pages
            )
            all_resources[paper_id] = resources
        except Exception as e:
            print(f"Failed to generate resources for {paper_id}: {e}")
    return all_resources
```

### ä¼ ç»Ÿå›¾åƒåˆ†æåŠŸèƒ½
```python
# æå–è®ºæ–‡å›¾è¡¨å’Œå…¬å¼ï¼ˆä¼ ç»Ÿæ–¹å¼ï¼‰
async def extract_paper_visuals(paper_id, max_pages=5):
    images = await read_paper_as_images(
        paper_id=paper_id, 
        max_pages=max_pages,
        dpi=200  # é«˜åˆ†è¾¨ç‡ç”¨äºæ›´å¥½çš„è¯†åˆ«
    )
    
    # è¿”å›å¯ç”¨äº AI è§†è§‰åˆ†æçš„å›¾åƒæ•°æ®
    return [
        {
            "page": img["page_number"],
            "image_b64": img["image_data"],
            "size": len(img["image_data"])
        }
        for img in images
    ]

# å¯¹æ¯”ä¸åŒè®ºæ–‡çš„è§†è§‰å¸ƒå±€
async def compare_paper_layouts(paper_ids):
    layouts = {}
    for paper_id in paper_ids:
        images = await read_paper_as_images(paper_id=paper_id, max_pages=1)
        if images:
            layouts[paper_id] = images[0]["image_data"]
    return layouts
```

## æµ‹è¯•é…ç½®

é…ç½®å®Œæˆåï¼Œå¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹å¼æµ‹è¯•ï¼š

1. **é‡å¯ Claude Desktop**
2. **æ£€æŸ¥å·¥å…·å¯ç”¨æ€§**ï¼šåœ¨ Claude ä¸­è¯¢é—® "æœ‰å“ªäº›å¯ç”¨çš„å·¥å…·ï¼Ÿ"
3. **æµ‹è¯•åŸºæœ¬åŠŸèƒ½**ï¼šå°è¯•æœç´¢ä¸€ç¯‡è®ºæ–‡

```bash
# æµ‹è¯•å‘½ä»¤ç¤ºä¾‹
python arxiv_server.py --transport http --port 8000
curl http://localhost:8000/arxiv/health
```

## æ€»ç»“

arXiv MCP æœåŠ¡å™¨ä¸ºå­¦æœ¯ç ”ç©¶æä¾›äº†å¼ºå¤§çš„å·¥å…·é›†ï¼Œé€šè¿‡åˆç†çš„æœç´¢ç­–ç•¥å’Œæ‰¹é‡æ“ä½œï¼Œå¯ä»¥å¤§å¤§æé«˜ç ”ç©¶æ•ˆç‡ã€‚å»ºè®®ä»ç®€å•çš„å…³é”®è¯æœç´¢å¼€å§‹ï¼Œé€æ­¥æŒæ¡é«˜çº§æœç´¢è¯­æ³•å’Œæ‰¹é‡æ“ä½œæŠ€å·§ã€‚
